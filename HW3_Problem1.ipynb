{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3_Problem1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc4Y_P253dnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scrapy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIeduahqC67V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time \n",
        "import requests\n",
        "from scrapy.http import TextResponse "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw5ChfOgDFhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url=\"http://books.toscrape.com/\"\n",
        "base_url = \"http://books.toscrape.com/catalogue/\"\n",
        "base_url1 = \"http://books.toscrape.com/\"\n",
        "page = requests.get(url)\n",
        "response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6TeGKyzRpKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining functions for title, rating, price, book page, book image,\n",
        "# availability in order to scrape the first page of the website.\n",
        "# In addition, creating functions for individual page, genre and descriptions\n",
        "# for further use. \n",
        "\n",
        "def get_title(url):\n",
        "  page = requests.get(url)\n",
        "  response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "  title = response.css(\"a[title]::attr(title)\").extract()\n",
        "  return title\n",
        "  \n",
        "def get_rating(url):\n",
        "  page = requests.get(url)\n",
        "  response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "  rating =response.css(\"p[class^='star-rating']::attr(class)\").extract()\n",
        "  return rating \n",
        "\n",
        "def get_price(url):\n",
        "  page = requests.get(url)\n",
        "  response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "  price = response.css(\"p.price_color::text\").extract()\n",
        "  price = [i.replace(\"Â£\", \" \") for i in price]\n",
        "  return price\n",
        "\n",
        "def get_book_page(url):\n",
        "  page = requests.get(url)\n",
        "  response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "  book_page = [base_url +i for i in response.css(\"a[title]::attr(href)\").extract()]\n",
        "  return book_page \n",
        "\n",
        "def get_book_picture(url):\n",
        "  page = requests.get(url)\n",
        "  response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "  book_picture_url = response.css(\"img::attr(src)\").extract()\n",
        "  book_picture = [base_url1 +i for i in book_picture_url]\n",
        "  return book_picture\n",
        "\n",
        "def get_availabilities(url):\n",
        "  page = requests.get(url)\n",
        "  response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "  availability = response.xpath(\"//p[contains(@class,'stock')]/text()[2]\").re(\"\\w+.+\\w\")\n",
        "  return availability\n",
        "\n",
        "def individual_page_url(url):\n",
        "    page = requests.get(url)\n",
        "    response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "    individual_page = [base_url+'catalogue/'+i for i in response.css('article.product_pod > div.image_container > a::attr(href)').extract()] #or title \n",
        "    return individual_page\n",
        "\n",
        "def book_genre(url): \n",
        "  page = requests.get(url)\n",
        "  response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "  genre = response.xpath(\"//ul[@class = 'breadcrumb']/li[3]/a/text()\").extract_first()\n",
        "  return genre\n",
        "\n",
        "def book_description(url):\n",
        "    page = requests.get(url)\n",
        "    response = TextResponse(url=page.url,body=page.text,encoding=\"utf-8\")\n",
        "    description = response.css(\"article.product_page > p::text\").extract_first()\n",
        "    return description\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9FJ1KWIBY6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Writing a code all_pages in order to scrape all of the pages.\n",
        "# The amount of pages is equal to 50.\n",
        "all_pages = [base_url+\"catalogue/page-{}.html\".format(i) for i in range(1,51)]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb3b4601BaCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating empty lists and extending them with first scraped page in order \n",
        "# to receive all the necessary data for all pages. \n",
        "all_titles = []\n",
        "all_ratings = []\n",
        "all_prices = []\n",
        "all_book_pages = []\n",
        "all_book_pictures = []\n",
        "all_availabilities = []\n",
        "individual_page = []\n",
        "for i in all_pages:\n",
        "    all_titles.extend(get_title(i))\n",
        "    all_ratings.extend(get_rating(i))\n",
        "    all_prices.extend(get_price(i))\n",
        "    all_book_pages.extend(get_book_page(i))\n",
        "    all_book_pictures.extend(get_book_picture(i))\n",
        "    all_availabilities.extend(get_availabilities(i))\n",
        "    individual_page.extend(individual_page_url(i))\n",
        "    time.sleep(1)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCMNHVBGNfAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating separately empty lists for genre and descriptions and \n",
        "# append them to our previously made functions and scraping usinf individual_page. \n",
        "books_genre = []\n",
        "books_descriptions = []\n",
        "for i in individual_page:\n",
        "    books_genre.append(book_genre(i))\n",
        "    books_descriptions.append(book_description(i))\n",
        "    time.sleep(1)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkVJh9eXQbLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a dataframe and turning it into csv file.\n",
        "df = pd.DataFrame(np.column_stack([all_titles, all_ratings, all_prices, all_book_pages, all_book_pictures, all_availabilities, individual_page, books_genre, books_descriptions]), columns = ['Titles', 'Ratings', 'Prices', 'Book_Pages', 'Book_Pictures', 'Availabilities', 'Individual_Page', 'Books_Genre', 'Books_Descriptions'])"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggyPbSbNRdRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " df.to_csv('all_books.csv', index=False) "
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjK5mssMRh7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"all_books.csv\")"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fei7-YGURmG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f280fe2e-76e5-46b4-aa3a-dfe4c62719e8"
      },
      "source": [
        "# Question 1. Calculating the average price of all books \n",
        "# using mean() function.  \n",
        "data[\"Prices\"].mean()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35.07034999999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuNw9pwMRvOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b194e2c7-b7f2-4aa7-a8a0-2f59812e0e51"
      },
      "source": [
        "# Question 2. Grouping prices by genre, calculating the mean, and using\n",
        "# sort_values() function in order to see on average which genre is the most expensive one. \n",
        "# Therefore, the answer is \"Suspense.\"\n",
        "data['Prices'].groupby(data['Books_Genre']).mean().sort_values(ascending = False).head(1)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Books_Genre\n",
              "Suspense    58.33\n",
              "Name: Prices, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KdDf5n0VZCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question 3. In order to calculate the correlation, we need\n",
        "# to replace our string with numbers. Afterwards, we can calculate \n",
        "# the correlation and see whether more expensive books are also rated \n",
        "# higher. The answer is 0.028, which means that there is a very weak positive relationship\n",
        "# between our variables. However, it's not enough to say that those books with higher prices \n",
        "# have higher ratings. \n",
        "data.Ratings[data.Ratings == 'star-rating One'] = 1\n",
        " data.Ratings[data.Ratings == 'star-rating Two'] = 2\n",
        "data.Ratings[data.Ratings == 'star-rating Three'] = 3\n",
        "data.Ratings[data.Ratings == 'star-rating Four'] = 4\n",
        "data.Ratings[data.Ratings == 'star-rating Five'] = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcZC-cXnUTBM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e53d8d3-8c86-4c10-9937-06bca54033cd"
      },
      "source": [
        "data[\"Prices\"].corr(data[\"Ratings\"])"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.028166239485873015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWwh8ceaWpLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}