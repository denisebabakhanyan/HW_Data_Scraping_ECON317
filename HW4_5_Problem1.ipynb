{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4_5_Problem1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2cXgYS_EVkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install scrapy\n",
        "#!pip install selenium"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKW3StNsw1qO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing all of the necessary packages. \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import time\n",
        "import re\n",
        "import requests\n",
        "import scrapy\n",
        "from scrapy.http import TextResponse\n",
        "from itertools import combinations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht-9_ERcEdCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Identifying the location of chromedriver on my computer. \n",
        "PATH = r\"/Users/apple/Downloads/chromedriver\"\n",
        "options = Options()\n",
        "options.headless = True\n",
        "URL = \"http://rate.am/en/armenian-dram-exchange-rates/central-bank-armenia\"\n",
        "browser = webdriver.Chrome(PATH)\n",
        "browser.get(URL)\n",
        "time.sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KLpJMrbEfjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Since the task asks to scrape all the info for 3 years for all months, it'll be convenient \n",
        "# to create seperate lists, and after that append the scraped data. Our main table consists of \n",
        "# Days, and all months, therefore, I created empty lists for all the criterias for 2018, 2019, and 2020.\n",
        "# We're scraping the necessary data and filtering it, appending to our lists, and then creating a DataFrame. \n",
        "# I went for the USD, therefore, I have USD_2018, USD_2019, USD_2020 DataFrames. \n",
        "Months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
        "Years = [\"2018\", \"2019\", \"2020\"]\n",
        "for i in Years:\n",
        "    year = browser.find_element_by_xpath(f'//select[@name=\"ctl00$Content$dlYear\"]/option[@value={i}]')\n",
        "    year.click()\n",
        "    time.sleep(1)\n",
        "    page = browser.page_source\n",
        "    response = TextResponse(body = page, url = URL, encoding = \"utf-8\")\n",
        "    if response.xpath(f'//select[@name=\"ctl00$Content$dlYear\"]/option[@selected=\"selected\"][@value=\"{i}\"]'):\n",
        "        Days_2018 = []\n",
        "        January_2018 = []\n",
        "        February_2018 = []\n",
        "        March_2018  = []\n",
        "        April_2018 = []\n",
        "        May_2018 = []\n",
        "        June_2018 = []\n",
        "        July_2018 = []\n",
        "        August_2018 = []\n",
        "        September_2018 = []\n",
        "        October_2018 = []\n",
        "        November_2018 = []\n",
        "        December_2018 = []\n",
        "        Days_2019 = []\n",
        "        January_2019 = []\n",
        "        February_2019 = []\n",
        "        March_2019 = []\n",
        "        April_2019 = []\n",
        "        May_2019 = []\n",
        "        June_2019 = []\n",
        "        July_2019 = []\n",
        "        August_2019 = []\n",
        "        September_2019 = []\n",
        "        October_2019 = []\n",
        "        November_2019 = []\n",
        "        December_2019 = []\n",
        "        Days_2020 = []\n",
        "        January_2020 = []\n",
        "        February_2020 = []\n",
        "        March_2020 = []\n",
        "        April_2020 = []\n",
        "        May_2020 = []\n",
        "        June_2020 = []\n",
        "        July_2020 = []\n",
        "        August_2020 = []\n",
        "        September_2020 = []\n",
        "        October_2020 = []\n",
        "        November_2020 = []\n",
        "        December_2020 = []\n",
        "        \n",
        "        for j in range (2,33):\n",
        "\n",
        "            days = response.xpath(f\"//table[@class='cb']/tbody/tr[{j}]/td[1]/text()\").extract()\n",
        "            days = days[0].strip()\n",
        "            january_raw = response.xpath(f\"//table[@class='cb']/tbody/tr[{j}]/td[2]/text()\").extract()\n",
        "            january = ' '.join([str(elem) for elem in january_raw])\n",
        "            january = january.strip()\n",
        "            february_raw = response.xpath(f\"//table[@class='cb']/tbody/tr[{j}]/td[3]/text()\").extract()\n",
        "            february = ' '.join([str(elem) for elem in february_raw])\n",
        "            february = february.strip()\n",
        "            march_raw = response.xpath(f\"//table[@class='cb']/tbody/tr[{j}]/td[4]/text()\").extract()\n",
        "            march = ' '.join([str(elem) for elem in march_raw])\n",
        "            march = march.strip()\n",
        "            april_raw = response.xpath(f\"//table[@class='cb']/tbody/tr[{j}]/td[5]/text()\").extract()\n",
        "            april = ' '.join([str(elem) for elem in april_raw])\n",
        "            april = april.strip()\n",
        "            may_raw = response.xpath(f\"//table[@class='cb']/tbody/tr[{j}]/td[6]/text()\").extract()\n",
        "            may = ' '.join([str(elem) for elem in may_raw])\n",
        "            may = may.strip()\n",
        "            june_raw = response.xpath(f\"//table[@class='cb']/tbody/tr[{j}]/td[7]/text()\").extract()\n",
        "            june = ' '.join([str(elem) for elem in june_raw])\n",
        "            june = june.strip()\n",
        "            july_raw = response.xpath(f\"//table[@class='cb']/tbody/tr[{j}]/td[8]/text()\").extract()\n",
        "            july = ' '.join([str(elem) for elem in july_raw])\n",
        "            july = july.strip()\n",
        "            august_raw = response.xpath(f\"//table[@class='cb']/tbody/tr[{j}]/td[9]/text()\").extract()\n",
        "            august = ' '.join([str(elem) for elem in august_raw])\n",
        "            august = august.strip()\n",
        "            september_raw = response.xpath(f\"//table[@class='cb']/tbody/tr[{j}]/td[10]/text()\").extract()\n",
        "            september = ' '.join([str(elem) for elem in september_raw])\n",
        "            september = september.strip()\n",
        "            october_raw = response.xpath(f\"//table[@class='cb']/tbody/tr[{j}]/td[11]/text()\").extract()\n",
        "            october = ' '.join([str(elem) for elem in october_raw])\n",
        "            october = october.strip()\n",
        "            november_raw = response.xpath(f\"//table[@class='cb']/tbody/tr[{j}]/td[12]/text()\").extract()\n",
        "            november = ' '.join([str(elem) for elem in november_raw])\n",
        "            november = november.strip()\n",
        "            december_raw = response.xpath(f\"//table[@class='cb']/tbody/tr[{j}]/td[13]/text()\").extract()\n",
        "            december = ' '.join([str(elem) for elem in december_raw])\n",
        "            december = december.strip()\n",
        "            \n",
        "            if i == \"2018\":\n",
        "                Days_2018.append(days)\n",
        "                January_2018.append(january)\n",
        "                February_2018.append(february)\n",
        "                March_2018.append(march)\n",
        "                April_2018.append(april)\n",
        "                May_2018.append(may)\n",
        "                June_2018.append(june)\n",
        "                July_2018.append(july)\n",
        "                August_2018.append(august)\n",
        "                September_2018.append(september)\n",
        "                October_2018.append(october)\n",
        "                November_2018.append(november)\n",
        "                December_2018.append(december)\n",
        "                USD_2018 = pd.DataFrame({\"Days\": Days_2018, \"January\": January_2018, \"February\": February_2018, \"March\": March_2018, \"April\": April_2018, \"May\": May_2018, \"June\": June_2018, \"July\": July_2018, \"August\": August_2018, \"September\": September_2018, \"October\": October_2018, \"November\": November_2018, \"December\": December_2018})\n",
        "                \n",
        "            if i == \"2019\":\n",
        "                Days_2019.append(days)\n",
        "                January_2019.append(january)\n",
        "                February_2019.append(february)\n",
        "                March_2019.append(march)\n",
        "                April_2019.append(april)\n",
        "                May_2019.append(may)\n",
        "                June_2019.append(june)\n",
        "                July_2019.append(july)\n",
        "                August_2019.append(august)\n",
        "                September_2019.append(september)\n",
        "                October_2019.append(october)\n",
        "                November_2019.append(november)\n",
        "                December_2019.append(december)\n",
        "                USD_2019 = pd.DataFrame({\"Days\": Days_2019, \"January\": January_2019, \"February\": February_2019, \"March\": March_2019, \"April\": April_2019, \"May\": May_2019, \"June\": June_2019, \"July\": July_2019, \"August\": August_2019, \"September\": September_2019, \"October\": October_2019, \"November\": November_2019, \"December\": December_2019})\n",
        "                \n",
        "            if i == \"2020\":\n",
        "                Days_2020.append(days)\n",
        "                January_2020.append(january)\n",
        "                February_2020.append(february)\n",
        "                March_2020.append(march)\n",
        "                April_2020.append(april)\n",
        "                May_2020.append(may)\n",
        "                June_2020.append(june)\n",
        "                July_2020.append(july)\n",
        "                August_2020.append(august)\n",
        "                September_2020.append(september)\n",
        "                October_2020.append(october)\n",
        "                November_2020.append(november)\n",
        "                December_2020.append(december)\n",
        "                USD_2020 = pd.DataFrame({\"Days\": Days_2020, \"January\": January_2020, \"February\": February_2020, \"March\": March_2020, \"April\": April_2020, \"May\": May_2020, \"June\": June_2020, \"July\": July_2020, \"August\": August_2020, \"September\": September_2020, \"October\": October_2020, \"November\": November_2020, \"December\": December_2020})\n",
        "\n",
        "browser.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY4I6YGzF1X6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning and converting the necessary data for further calculations. \n",
        "USD_2018_clean = USD_2018.replace(\"X\", \"NaN\").replace(\"\", \"NaN\")\n",
        "USD_2019_clean = USD_2019.replace(\"X\", \"NaN\").replace(\"\", \"NaN\")\n",
        "del USD_2018_clean['Days']\n",
        "for i in USD_2018_clean:\n",
        "    USD_2018_clean[f\"{i}\"] = pd.to_numeric(USD_2018_clean[f\"{i}\"], downcast = \"float\", errors='coerce')\n",
        "del USD_2019_clean['Days']\n",
        "for i in USD_2019_clean:\n",
        "    USD_2019_clean[f\"{i}\"] = pd.to_numeric(USD_2019_clean[f\"{i}\"], downcast = \"float\", errors='coerce')\n",
        "for i in Months:\n",
        "    m_to_m_dif = USD_2019_clean.sub(USD_2019_clean, axis = i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EduPWP2QJ_nP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question 1. Calculating annual variation both for 2018 and 2019 using simple var() function. \n",
        "# 2018: approximately 1.153459\n",
        "# 2019: approximately 1.153459\n",
        "var_2018 = str(USD_2018_clean.var().mean())\n",
        "var_2019 = str(USD_2018_clean.var().mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf-wqxAiKmSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question 2. Calculating month to month variation of differences using the same logic. \n",
        "# Answer: 2.134759\n",
        "m_to_m_var = str(m_to_m_dif.var().mean())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}